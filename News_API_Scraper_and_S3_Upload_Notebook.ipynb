{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/giuliobarde/web_data_mining_project/blob/main/News_API_Scraper_and_S3_Upload_Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# News API Scraper and S3 Upload Notebook\n",
        "\n",
        "This notebook scrapes the past month's news content from the News API, partitions the articles into three compartments based on authorship (multiple authors, single author, and no authors), and uploads the resulting notebooks to your team's S3 bucket folder."
      ],
      "metadata": {
        "id": "4vSi1GYJcQea"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install boto3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_qXQv6ocgFH",
        "outputId": "0fedf4b3-bc9c-43fb-b135-3f1ddecc8881"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting boto3\n",
            "  Downloading boto3-1.37.11-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting botocore<1.38.0,>=1.37.11 (from boto3)\n",
            "  Downloading botocore-1.37.11-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.12.0,>=0.11.0 (from boto3)\n",
            "  Downloading s3transfer-0.11.4-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.11/dist-packages (from botocore<1.38.0,>=1.37.11->boto3) (2.8.2)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.11/dist-packages (from botocore<1.38.0,>=1.37.11->boto3) (2.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.38.0,>=1.37.11->boto3) (1.17.0)\n",
            "Downloading boto3-1.37.11-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.6/139.6 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading botocore-1.37.11-py3-none-any.whl (13.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m57.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading s3transfer-0.11.4-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.4/84.4 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jmespath, botocore, s3transfer, boto3\n",
            "Successfully installed boto3-1.37.11 botocore-1.37.11 jmespath-1.0.1 s3transfer-0.11.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "zokNEzsqcKjM"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import requests\n",
        "import datetime\n",
        "import boto3\n",
        "from botocore.config import Config\n",
        "from botocore import UNSIGNED\n",
        "from collections import defaultdict\n",
        "\n",
        "# Create a temporary directory if it doesn't exist\n",
        "if not os.path.exists('tmp'):\n",
        "    os.makedirs('tmp')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# S3 Configuration\n",
        "TEAM = \"TEAM_1/\"  # Your team folder\n",
        "BUCKET_NAME = \"cus635-spring2025\"\n",
        "\n",
        "# Create an anonymous S3 client (using UNSIGNED credentials)\n",
        "s3 = boto3.client('s3', config=Config(signature_version=UNSIGNED))"
      ],
      "metadata": {
        "id": "NG-xNCJUcV5P"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# News API Scraping with adjusted date range\n",
        "news_key = '116a9d5a70be4a3689c7b732a1a547d4'\n",
        "\n",
        "# Calculate date range for the past month\n",
        "end_date = datetime.datetime.utcnow()\n",
        "start_date = end_date - datetime.timedelta(days=30)\n",
        "\n",
        "allowed_start = datetime.datetime(2025, 2, 11)\n",
        "if start_date < allowed_start:\n",
        "    start_date = allowed_start\n",
        "\n",
        "# Format dates as YYYY-MM-DD\n",
        "end_str = end_date.strftime('%Y-%m-%d')\n",
        "start_str = start_date.strftime('%Y-%m-%d')\n",
        "\n",
        "# Defined query to get sports articles\n",
        "query1 = 'sport'\n",
        "url1 = (f'https://newsapi.org/v2/top-headlines?q={query1}&from={start_str}&to={end_str}&sortBy=popularity&apiKey={news_key}')\n",
        "response1 = requests.get(url1)\n",
        "\n",
        "# Same for bitcoin articles\n",
        "query2 = 'bitcoin'\n",
        "url2 = (f'https://newsapi.org/v2/everything?q={query2}&from={start_str}&to={end_str}&sortBy=popularity&apiKey={news_key}')\n",
        "response2 = requests.get(url2)\n",
        "\n",
        "# Same for government articles\n",
        "query3 = 'government'\n",
        "url3 = (f'https://newsapi.org/v2/top-headlines?q={query3}&from={start_str}&to={end_str}&sortBy=popularity&apiKey={news_key}')\n",
        "response3 = requests.get(url3)\n",
        "\n",
        "data1 = response1.json()\n",
        "data2 = response2.json()\n",
        "data3 = response3.json()\n",
        "\n",
        "# Gets the source for each article\n",
        "def print_source_counts(data, label):\n",
        "    sources = defaultdict(list)\n",
        "    for article in data.get('articles', []):\n",
        "        source_name = article.get('source', {}).get('name', 'Unknown')\n",
        "        sources[source_name].append(article)\n",
        "    for src, articles in sources.items():\n",
        "        print(f\"  {src}: {len(articles)} articles\")\n",
        "\n",
        "# Process and print the results for each dataset by source\n",
        "print_source_counts(data1, 'data1')\n",
        "print_source_counts(data2, 'data2')\n",
        "print_source_counts(data3, 'data3')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ulinoRtecpLm",
        "outputId": "2c94c2f2-259c-4edb-9000-3d2e410d9e4a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Bild: 2 articles\n",
            "  Fox Sports: 1 articles\n",
            "  BBC Sport: 3 articles\n",
            "  FourFourTwo: 1 articles\n",
            "  Il Sole 24 Ore: 1 articles\n",
            "  Google News (India): 1 articles\n",
            "  Le Monde: 1 articles\n",
            "  Politico: 1 articles\n",
            "  TalkSport: 1 articles\n",
            "  Bleacher Report: 2 articles\n",
            "  ANSA.it: 1 articles\n",
            "  L'equipe: 1 articles\n",
            "  The Irish Times: 1 articles\n",
            "  The Hindu: 1 articles\n",
            "  The Times of India: 1 articles\n",
            "  Wired: 1 articles\n",
            "  The Verge: 2 articles\n",
            "  Gizmodo.com: 9 articles\n",
            "  BBC News: 3 articles\n",
            "  CNET: 1 articles\n",
            "  Business Insider: 6 articles\n",
            "  NPR: 3 articles\n",
            "  Slashdot.org: 2 articles\n",
            "  Yahoo Entertainment: 10 articles\n",
            "  Time: 1 articles\n",
            "  ESPN: 1 articles\n",
            "  Xataka.com: 10 articles\n",
            "  ABC News: 9 articles\n",
            "  Fox News: 1 articles\n",
            "  Le Monde: 1 articles\n",
            "  Digital Trends: 1 articles\n",
            "  The Atlantic: 1 articles\n",
            "  Obscura.net: 2 articles\n",
            "  Kaspersky.com: 1 articles\n",
            "  Zeteo.com: 1 articles\n",
            "  Github.com: 1 articles\n",
            "  Startupbaniya.com: 1 articles\n",
            "  Pluralistic.net: 1 articles\n",
            "  Educatedguesswork.org: 1 articles\n",
            "  heise online: 16 articles\n",
            "  Genbeta.com: 2 articles\n",
            "  MarketWatch: 3 articles\n",
            "  CoinDesk: 1 articles\n",
            "  AppleInsider: 1 articles\n",
            "  Gizmodo.jp: 2 articles\n",
            "  Journal du geek: 1 articles\n",
            "  Flowingdata.com: 1 articles\n",
            "  Theregister.com: 1 articles\n",
            "  CBS News: 2 articles\n",
            "  The Washington Post: 1 articles\n",
            "  The Wall Street Journal: 2 articles\n",
            "  Bloomberg: 1 articles\n",
            "  ABC News (AU): 1 articles\n",
            "  Breitbart News: 1 articles\n",
            "  The Hill: 3 articles\n",
            "  Google News: 1 articles\n",
            "  NBC News: 2 articles\n",
            "  Wired: 1 articles\n",
            "  News.com.au: 1 articles\n",
            "  The Verge: 1 articles\n",
            "  Crypto Coins News: 1 articles\n",
            "  BBC News: 1 articles\n",
            "  Associated Press: 1 articles\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine articles from the 3 datasets\n",
        "all_articles = data1.get('articles', []) + data2.get('articles', []) + data3.get('articles', [])\n",
        "\n",
        "# Print the total number of all articles\n",
        "print(f\"Total articles: {len(all_articles)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oOuqEDijcsJ2",
        "outputId": "fe0adef8-1d87-4293-af61-2df8c0fb5aef"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total articles: 137\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def sanitize_filename(name):\n",
        "    # Replace spaces and non-alphanumeric characters with underscores\n",
        "    return re.sub(r'\\W+', '_', name)\n",
        "\n",
        "# Create a directory for source notebooks if it doesn't exist\n",
        "source_dir = \"tmp/sources\"\n",
        "if not os.path.exists(source_dir):\n",
        "    os.makedirs(source_dir)\n",
        "\n",
        "\n",
        "# Create a directory for source JSON files if it doesn't exist\n",
        "raw_source_dir = \"tmp/sources_raw\"\n",
        "if not os.path.exists(raw_source_dir):\n",
        "    os.makedirs(raw_source_dir)\n",
        "\n",
        "# Create a dictionary for each source with an 'id' key for each article (assuming each article has a unique id)\n",
        "for src, art_list in sources.items():\n",
        "    # For this example, we simply use the index in the list\n",
        "    articles_by_id = {str(index): article for index, article in enumerate(art_list)}\n",
        "    sanitized_src = sanitize_filename(src)\n",
        "    filepath = f\"{raw_source_dir}/{sanitized_src}.json\"\n",
        "    with open(filepath, 'w') as f:\n",
        "        json.dump(articles_by_id, f, indent=2)\n",
        "    print(f\"Created raw JSON file for {src}: {filepath}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w2eDXFFPhL4P",
        "outputId": "3e12877b-a3b6-43c5-931f-2496d932e1e3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created raw JSON file for Bild: tmp/sources_raw/Bild.json\n",
            "Created raw JSON file for BBC Sport: tmp/sources_raw/BBC_Sport.json\n",
            "Created raw JSON file for Fox Sports: tmp/sources_raw/Fox_Sports.json\n",
            "Created raw JSON file for FourFourTwo: tmp/sources_raw/FourFourTwo.json\n",
            "Created raw JSON file for Il Sole 24 Ore: tmp/sources_raw/Il_Sole_24_Ore.json\n",
            "Created raw JSON file for Le Monde: tmp/sources_raw/Le_Monde.json\n",
            "Created raw JSON file for Politico: tmp/sources_raw/Politico.json\n",
            "Created raw JSON file for TalkSport: tmp/sources_raw/TalkSport.json\n",
            "Created raw JSON file for Bleacher Report: tmp/sources_raw/Bleacher_Report.json\n",
            "Created raw JSON file for ANSA.it: tmp/sources_raw/ANSA_it.json\n",
            "Created raw JSON file for L'equipe: tmp/sources_raw/L_equipe.json\n",
            "Created raw JSON file for The Irish Times: tmp/sources_raw/The_Irish_Times.json\n",
            "Created raw JSON file for The Hindu: tmp/sources_raw/The_Hindu.json\n",
            "Created raw JSON file for The Times of India: tmp/sources_raw/The_Times_of_India.json\n",
            "Created raw JSON file for Wired: tmp/sources_raw/Wired.json\n",
            "Created raw JSON file for The Verge: tmp/sources_raw/The_Verge.json\n",
            "Created raw JSON file for Gizmodo.com: tmp/sources_raw/Gizmodo_com.json\n",
            "Created raw JSON file for BBC News: tmp/sources_raw/BBC_News.json\n",
            "Created raw JSON file for CNET: tmp/sources_raw/CNET.json\n",
            "Created raw JSON file for Business Insider: tmp/sources_raw/Business_Insider.json\n",
            "Created raw JSON file for NPR: tmp/sources_raw/NPR.json\n",
            "Created raw JSON file for Slashdot.org: tmp/sources_raw/Slashdot_org.json\n",
            "Created raw JSON file for Yahoo Entertainment: tmp/sources_raw/Yahoo_Entertainment.json\n",
            "Created raw JSON file for Time: tmp/sources_raw/Time.json\n",
            "Created raw JSON file for ESPN: tmp/sources_raw/ESPN.json\n",
            "Created raw JSON file for Xataka.com: tmp/sources_raw/Xataka_com.json\n",
            "Created raw JSON file for ABC News: tmp/sources_raw/ABC_News.json\n",
            "Created raw JSON file for Fox News: tmp/sources_raw/Fox_News.json\n",
            "Created raw JSON file for Digital Trends: tmp/sources_raw/Digital_Trends.json\n",
            "Created raw JSON file for The Atlantic: tmp/sources_raw/The_Atlantic.json\n",
            "Created raw JSON file for Obscura.net: tmp/sources_raw/Obscura_net.json\n",
            "Created raw JSON file for Kaspersky.com: tmp/sources_raw/Kaspersky_com.json\n",
            "Created raw JSON file for Zeteo.com: tmp/sources_raw/Zeteo_com.json\n",
            "Created raw JSON file for Github.com: tmp/sources_raw/Github_com.json\n",
            "Created raw JSON file for Startupbaniya.com: tmp/sources_raw/Startupbaniya_com.json\n",
            "Created raw JSON file for Pluralistic.net: tmp/sources_raw/Pluralistic_net.json\n",
            "Created raw JSON file for Educatedguesswork.org: tmp/sources_raw/Educatedguesswork_org.json\n",
            "Created raw JSON file for heise online: tmp/sources_raw/heise_online.json\n",
            "Created raw JSON file for Genbeta.com: tmp/sources_raw/Genbeta_com.json\n",
            "Created raw JSON file for MarketWatch: tmp/sources_raw/MarketWatch.json\n",
            "Created raw JSON file for CoinDesk: tmp/sources_raw/CoinDesk.json\n",
            "Created raw JSON file for AppleInsider: tmp/sources_raw/AppleInsider.json\n",
            "Created raw JSON file for Gizmodo.jp: tmp/sources_raw/Gizmodo_jp.json\n",
            "Created raw JSON file for Journal du geek: tmp/sources_raw/Journal_du_geek.json\n",
            "Created raw JSON file for Flowingdata.com: tmp/sources_raw/Flowingdata_com.json\n",
            "Created raw JSON file for Theregister.com: tmp/sources_raw/Theregister_com.json\n",
            "Created raw JSON file for CBC News: tmp/sources_raw/CBC_News.json\n",
            "Created raw JSON file for CBS News: tmp/sources_raw/CBS_News.json\n",
            "Created raw JSON file for The Wall Street Journal: tmp/sources_raw/The_Wall_Street_Journal.json\n",
            "Created raw JSON file for Bloomberg: tmp/sources_raw/Bloomberg.json\n",
            "Created raw JSON file for ABC News (AU): tmp/sources_raw/ABC_News_AU_.json\n",
            "Created raw JSON file for The Hill: tmp/sources_raw/The_Hill.json\n",
            "Created raw JSON file for NBC News: tmp/sources_raw/NBC_News.json\n",
            "Created raw JSON file for News.com.au: tmp/sources_raw/News_com_au.json\n",
            "Created raw JSON file for Breitbart News: tmp/sources_raw/Breitbart_News.json\n",
            "Created raw JSON file for Crypto Coins News: tmp/sources_raw/Crypto_Coins_News.json\n",
            "Created raw JSON file for The Washington Post: tmp/sources_raw/The_Washington_Post.json\n",
            "Created raw JSON file for Associated Press: tmp/sources_raw/Associated_Press.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload each raw JSON file from the sources_raw directory to S3\n",
        "for filename in os.listdir(raw_source_dir):\n",
        "    local_path = f\"{raw_source_dir}/{filename}\"\n",
        "    # Upload files to the \"sources\" subfolder under your team folder in S3\n",
        "    s3_key = TEAM + \"sources/\" + filename\n",
        "    s3.upload_file(local_path, BUCKET_NAME, s3_key)\n",
        "    print(f\"Uploaded {local_path} to s3://{BUCKET_NAME}/{s3_key}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CfUykHDQlVFZ",
        "outputId": "7d62d145-44ba-4e5e-b3ca-9a7e0aa7cd96"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uploaded tmp/sources_raw/CoinDesk.json to s3://cus635-spring2025/TEAM_1/sources/CoinDesk.json\n",
            "Uploaded tmp/sources_raw/Il_Sole_24_Ore.json to s3://cus635-spring2025/TEAM_1/sources/Il_Sole_24_Ore.json\n",
            "Uploaded tmp/sources_raw/Fox_News.json to s3://cus635-spring2025/TEAM_1/sources/Fox_News.json\n",
            "Uploaded tmp/sources_raw/Bloomberg.json to s3://cus635-spring2025/TEAM_1/sources/Bloomberg.json\n",
            "Uploaded tmp/sources_raw/Flowingdata_com.json to s3://cus635-spring2025/TEAM_1/sources/Flowingdata_com.json\n",
            "Uploaded tmp/sources_raw/Genbeta_com.json to s3://cus635-spring2025/TEAM_1/sources/Genbeta_com.json\n",
            "Uploaded tmp/sources_raw/Bleacher_Report.json to s3://cus635-spring2025/TEAM_1/sources/Bleacher_Report.json\n",
            "Uploaded tmp/sources_raw/Digital_Trends.json to s3://cus635-spring2025/TEAM_1/sources/Digital_Trends.json\n",
            "Uploaded tmp/sources_raw/CBS_News.json to s3://cus635-spring2025/TEAM_1/sources/CBS_News.json\n",
            "Uploaded tmp/sources_raw/Slashdot_org.json to s3://cus635-spring2025/TEAM_1/sources/Slashdot_org.json\n",
            "Uploaded tmp/sources_raw/Time.json to s3://cus635-spring2025/TEAM_1/sources/Time.json\n",
            "Uploaded tmp/sources_raw/NPR.json to s3://cus635-spring2025/TEAM_1/sources/NPR.json\n",
            "Uploaded tmp/sources_raw/Zeteo_com.json to s3://cus635-spring2025/TEAM_1/sources/Zeteo_com.json\n",
            "Uploaded tmp/sources_raw/BBC_News.json to s3://cus635-spring2025/TEAM_1/sources/BBC_News.json\n",
            "Uploaded tmp/sources_raw/ANSA_it.json to s3://cus635-spring2025/TEAM_1/sources/ANSA_it.json\n",
            "Uploaded tmp/sources_raw/AppleInsider.json to s3://cus635-spring2025/TEAM_1/sources/AppleInsider.json\n",
            "Uploaded tmp/sources_raw/Bild.json to s3://cus635-spring2025/TEAM_1/sources/Bild.json\n",
            "Uploaded tmp/sources_raw/ABC_News_AU_.json to s3://cus635-spring2025/TEAM_1/sources/ABC_News_AU_.json\n",
            "Uploaded tmp/sources_raw/Theregister_com.json to s3://cus635-spring2025/TEAM_1/sources/Theregister_com.json\n",
            "Uploaded tmp/sources_raw/Kaspersky_com.json to s3://cus635-spring2025/TEAM_1/sources/Kaspersky_com.json\n",
            "Uploaded tmp/sources_raw/Xataka_com.json to s3://cus635-spring2025/TEAM_1/sources/Xataka_com.json\n",
            "Uploaded tmp/sources_raw/Gizmodo_jp.json to s3://cus635-spring2025/TEAM_1/sources/Gizmodo_jp.json\n",
            "Uploaded tmp/sources_raw/TalkSport.json to s3://cus635-spring2025/TEAM_1/sources/TalkSport.json\n",
            "Uploaded tmp/sources_raw/Breitbart_News.json to s3://cus635-spring2025/TEAM_1/sources/Breitbart_News.json\n",
            "Uploaded tmp/sources_raw/The_Washington_Post.json to s3://cus635-spring2025/TEAM_1/sources/The_Washington_Post.json\n",
            "Uploaded tmp/sources_raw/Gizmodo_com.json to s3://cus635-spring2025/TEAM_1/sources/Gizmodo_com.json\n",
            "Uploaded tmp/sources_raw/The_Hill.json to s3://cus635-spring2025/TEAM_1/sources/The_Hill.json\n",
            "Uploaded tmp/sources_raw/FourFourTwo.json to s3://cus635-spring2025/TEAM_1/sources/FourFourTwo.json\n",
            "Uploaded tmp/sources_raw/heise_online.json to s3://cus635-spring2025/TEAM_1/sources/heise_online.json\n",
            "Uploaded tmp/sources_raw/Yahoo_Entertainment.json to s3://cus635-spring2025/TEAM_1/sources/Yahoo_Entertainment.json\n",
            "Uploaded tmp/sources_raw/Le_Monde.json to s3://cus635-spring2025/TEAM_1/sources/Le_Monde.json\n",
            "Uploaded tmp/sources_raw/CNET.json to s3://cus635-spring2025/TEAM_1/sources/CNET.json\n",
            "Uploaded tmp/sources_raw/ESPN.json to s3://cus635-spring2025/TEAM_1/sources/ESPN.json\n",
            "Uploaded tmp/sources_raw/NBC_News.json to s3://cus635-spring2025/TEAM_1/sources/NBC_News.json\n",
            "Uploaded tmp/sources_raw/Journal_du_geek.json to s3://cus635-spring2025/TEAM_1/sources/Journal_du_geek.json\n",
            "Uploaded tmp/sources_raw/The_Wall_Street_Journal.json to s3://cus635-spring2025/TEAM_1/sources/The_Wall_Street_Journal.json\n",
            "Uploaded tmp/sources_raw/Pluralistic_net.json to s3://cus635-spring2025/TEAM_1/sources/Pluralistic_net.json\n",
            "Uploaded tmp/sources_raw/Crypto_Coins_News.json to s3://cus635-spring2025/TEAM_1/sources/Crypto_Coins_News.json\n",
            "Uploaded tmp/sources_raw/The_Atlantic.json to s3://cus635-spring2025/TEAM_1/sources/The_Atlantic.json\n",
            "Uploaded tmp/sources_raw/Github_com.json to s3://cus635-spring2025/TEAM_1/sources/Github_com.json\n",
            "Uploaded tmp/sources_raw/The_Times_of_India.json to s3://cus635-spring2025/TEAM_1/sources/The_Times_of_India.json\n",
            "Uploaded tmp/sources_raw/The_Verge.json to s3://cus635-spring2025/TEAM_1/sources/The_Verge.json\n",
            "Uploaded tmp/sources_raw/Educatedguesswork_org.json to s3://cus635-spring2025/TEAM_1/sources/Educatedguesswork_org.json\n",
            "Uploaded tmp/sources_raw/News_com_au.json to s3://cus635-spring2025/TEAM_1/sources/News_com_au.json\n",
            "Uploaded tmp/sources_raw/MarketWatch.json to s3://cus635-spring2025/TEAM_1/sources/MarketWatch.json\n",
            "Uploaded tmp/sources_raw/Wired.json to s3://cus635-spring2025/TEAM_1/sources/Wired.json\n",
            "Uploaded tmp/sources_raw/Startupbaniya_com.json to s3://cus635-spring2025/TEAM_1/sources/Startupbaniya_com.json\n",
            "Uploaded tmp/sources_raw/L_equipe.json to s3://cus635-spring2025/TEAM_1/sources/L_equipe.json\n",
            "Uploaded tmp/sources_raw/Business_Insider.json to s3://cus635-spring2025/TEAM_1/sources/Business_Insider.json\n",
            "Uploaded tmp/sources_raw/Associated_Press.json to s3://cus635-spring2025/TEAM_1/sources/Associated_Press.json\n",
            "Uploaded tmp/sources_raw/BBC_Sport.json to s3://cus635-spring2025/TEAM_1/sources/BBC_Sport.json\n",
            "Uploaded tmp/sources_raw/ABC_News.json to s3://cus635-spring2025/TEAM_1/sources/ABC_News.json\n",
            "Uploaded tmp/sources_raw/CBC_News.json to s3://cus635-spring2025/TEAM_1/sources/CBC_News.json\n",
            "Uploaded tmp/sources_raw/Obscura_net.json to s3://cus635-spring2025/TEAM_1/sources/Obscura_net.json\n",
            "Uploaded tmp/sources_raw/The_Irish_Times.json to s3://cus635-spring2025/TEAM_1/sources/The_Irish_Times.json\n",
            "Uploaded tmp/sources_raw/Fox_Sports.json to s3://cus635-spring2025/TEAM_1/sources/Fox_Sports.json\n",
            "Uploaded tmp/sources_raw/The_Hindu.json to s3://cus635-spring2025/TEAM_1/sources/The_Hindu.json\n",
            "Uploaded tmp/sources_raw/Politico.json to s3://cus635-spring2025/TEAM_1/sources/Politico.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# List files in the S3 bucket under the TEAM_1/sources/ folder to verify uploads\n",
        "response = s3.list_objects_v2(Bucket=BUCKET_NAME, Prefix=TEAM + \"sources/\")\n",
        "if 'Contents' in response:\n",
        "    print('Files in S3 Bucket under', TEAM + \"sources/\", ':')\n",
        "    for obj in response['Contents']:\n",
        "        print('-', obj['Key'])\n",
        "else:\n",
        "    print('No files found in the bucket under sources.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gu5OttSslnYm",
        "outputId": "c2301cb0-2d7b-406d-b190-63b56a75cfb9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files in S3 Bucket under TEAM_1/sources/ :\n",
            "- TEAM_1/sources/ABC_News.json\n",
            "- TEAM_1/sources/ABC_News_AU_.json\n",
            "- TEAM_1/sources/ANSA_it.json\n",
            "- TEAM_1/sources/AppleInsider.json\n",
            "- TEAM_1/sources/Associated_Press.json\n",
            "- TEAM_1/sources/BBC_News.json\n",
            "- TEAM_1/sources/BBC_Sport.json\n",
            "- TEAM_1/sources/Bild.json\n",
            "- TEAM_1/sources/Bleacher_Report.json\n",
            "- TEAM_1/sources/Bloomberg.json\n",
            "- TEAM_1/sources/Breitbart_News.json\n",
            "- TEAM_1/sources/Business_Insider.json\n",
            "- TEAM_1/sources/CBC_News.json\n",
            "- TEAM_1/sources/CBS_News.json\n",
            "- TEAM_1/sources/CNET.json\n",
            "- TEAM_1/sources/CoinDesk.json\n",
            "- TEAM_1/sources/Crypto_Coins_News.json\n",
            "- TEAM_1/sources/Digital_Trends.json\n",
            "- TEAM_1/sources/ESPN.json\n",
            "- TEAM_1/sources/Educatedguesswork_org.json\n",
            "- TEAM_1/sources/Flowingdata_com.json\n",
            "- TEAM_1/sources/FourFourTwo.json\n",
            "- TEAM_1/sources/Fox_News.json\n",
            "- TEAM_1/sources/Fox_Sports.json\n",
            "- TEAM_1/sources/Genbeta_com.json\n",
            "- TEAM_1/sources/Github_com.json\n",
            "- TEAM_1/sources/Gizmodo_com.json\n",
            "- TEAM_1/sources/Gizmodo_jp.json\n",
            "- TEAM_1/sources/Il_Sole_24_Ore.json\n",
            "- TEAM_1/sources/Journal_du_geek.json\n",
            "- TEAM_1/sources/Kaspersky_com.json\n",
            "- TEAM_1/sources/L_equipe.json\n",
            "- TEAM_1/sources/Le_Monde.json\n",
            "- TEAM_1/sources/MarketWatch.json\n",
            "- TEAM_1/sources/NBC_News.json\n",
            "- TEAM_1/sources/NPR.json\n",
            "- TEAM_1/sources/News_com_au.json\n",
            "- TEAM_1/sources/Obscura_net.json\n",
            "- TEAM_1/sources/Pluralistic_net.json\n",
            "- TEAM_1/sources/Politico.json\n",
            "- TEAM_1/sources/Slashdot_org.json\n",
            "- TEAM_1/sources/Startupbaniya_com.json\n",
            "- TEAM_1/sources/TalkSport.json\n",
            "- TEAM_1/sources/The_Atlantic.json\n",
            "- TEAM_1/sources/The_Hill.json\n",
            "- TEAM_1/sources/The_Hindu.json\n",
            "- TEAM_1/sources/The_Irish_Times.json\n",
            "- TEAM_1/sources/The_Times_of_India.json\n",
            "- TEAM_1/sources/The_Verge.json\n",
            "- TEAM_1/sources/The_Wall_Street_Journal.json\n",
            "- TEAM_1/sources/The_Washington_Post.json\n",
            "- TEAM_1/sources/Theregister_com.json\n",
            "- TEAM_1/sources/Time.json\n",
            "- TEAM_1/sources/Wired.json\n",
            "- TEAM_1/sources/Xataka_com.json\n",
            "- TEAM_1/sources/Yahoo_Entertainment.json\n",
            "- TEAM_1/sources/Zeteo_com.json\n",
            "- TEAM_1/sources/heise_online.json\n"
          ]
        }
      ]
    }
  ]
}